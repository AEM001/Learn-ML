{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b65d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "\n",
    "torch_activation_dict={\n",
    "'identity':lambda x:x,\n",
    "'sigmoid':torch.sigmoid,\n",
    "'relu':torch.relu,\n",
    "'ranh':torch.tanh,\n",
    "}\n",
    "\n",
    "class MLP_torch(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_sizes,\n",
    "        use_bias=True,\n",
    "        activation='relu',\n",
    "        output_activation='identity',):\n",
    "        super().__init__()\n",
    "        self.activation = torch_activation_dict[activation]\n",
    "        self.output_activation = torch_activation_dict[output_activation]\n",
    "        self.layers = nn.ModuleList()\n",
    "        num_in=layer_sizes[0]\n",
    "        for num_out in layer_sizes[1:]:\n",
    "            self.layers.append(nn.Linear(num_in,num_out,bias=use_bias))#默认Kaiming初始化\n",
    "            # 正态分布初始化，采用与前面手动实现时相同的方式\n",
    "            normal_(self.layers[-1].weight, std=1.0)\n",
    "            # 偏置项为全0\n",
    "            self.layers[-1].bias.data.fill_(0.0)\n",
    "            num_in = num_out\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x=layer(x)\n",
    "            x=self.activation(x)\n",
    "\n",
    "        x=self.layers[-1](x)\n",
    "        x=self.output_activation(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731135d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "batch_size = 128\n",
    "eps = 1e-7\n",
    "torch.manual_seed(0)\n",
    "\n",
    "mlp=MLP_torch(layer_sizes=[2,4,1],use_bias=True,out_activation='sigmoid')\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "test_losses= []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    st=0\n",
    "    loss=[]\n",
    "    while True:\n",
    "        ed=min(st+batch_size,len(x_train))\n",
    "        if st>=ed:\n",
    "            break\n",
    "        x=torch.tensor(x_train[st:ed],dtype=torch.float32)\n",
    "        y=torch.tensor(y_train[st:ed],dtype=torch.float32)\n",
    "        y_pred = mlp(x)\n",
    "        train_loss=torch.mean(-y * torch.log(y_pred + eps) \\\n",
    "            - (1 - y) * torch.log(1 - y_pred + eps))\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss.append(train_loss.detach().numpy())\n",
    "        st+= batch_size\n",
    "\n",
    "    losses.append(sum(loss)/len(loss))\n",
    "    with torch.inference_mode():\n",
    "        x = torch.tensor(x_test, dtype=torch.float32)\n",
    "        y = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "        y_pred = mlp(x)\n",
    "        test_loss = torch.sum(-y * torch.log(y_pred + eps) \\\n",
    "            - (1 - y) * torch.log(1 - y_pred + eps)) / len(x_test)\n",
    "        test_acc = torch.sum(torch.round(y_pred) == y) / len(x_test)\n",
    "        test_losses.append(test_loss.detach().numpy())\n",
    "        test_accs.append(test_acc.detach().numpy())\n",
    "\n",
    "print('测试精度：', test_accs[-1])\n",
    "# 将损失变化进行可视化\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plt.plot(losses, color='blue', label='train loss')\n",
    "plt.plot(test_losses, color='red', ls='--', label='test loss')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Cross-Entropy Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(test_accs, color='red')\n",
    "plt.ylim(top=1.0)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
